{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import atexit\n",
    "import os\n",
    "import platform\n",
    "import warnings\n",
    "\n",
    "import py4j #** \n",
    "\n",
    "from pyspark import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(os.environ.get(\"SPARK_EXECUTOR_URI\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "environ({'ASSEMBLY_DIR2': '\"C:\\\\SPARK\\\\assembly\\\\target\\\\scala-2.11\"', 'QT_DEVICE_PIXEL_RATIO': 'auto', 'PROCESSOR_ARCHITECTURE': 'AMD64', 'HADOOP_HOME': 'C:\\\\HADOOP\\\\hadoop-2.7.1', 'WINDIR': 'C:\\\\WINDOWS', 'OS': 'Windows_NT', 'PROCESSOR_REVISION': '9e09', 'COMMONPROGRAMW6432': 'C:\\\\Program Files\\\\Common Files', 'NUMBER_OF_PROCESSORS': '8', 'PUBLIC': 'C:\\\\Users\\\\Public', 'SPARK_JARS_DIR': '\"C:\\\\SPARK\\\\jars\"', 'PYTHONSTARTUP': 'C:\\\\SPARK\\\\python\\\\pyspark\\\\shell.py', 'FPS_BROWSER_APP_PROFILE_STRING': 'Internet Explorer', 'PYSPARK_SUBMIT_ARGS': '\"--name\" \"PySparkShell\" \"pyspark-shell\" ', 'FIND_SPARK_HOME_PYTHON_SCRIPT': 'C:\\\\SPARK\\\\bin\\\\find_spark_home.py', 'PATH': 'C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\Library\\\\bin;C:\\\\JAVA\\\\bin;C:\\\\ProgramData\\\\DockerDesktop\\\\version-bin;C:\\\\Program Files\\\\Docker\\\\Docker\\\\Resources\\\\bin;C:\\\\Program Files (x86)\\\\Microsoft SDKs\\\\Azure\\\\CLI2\\\\wbin;C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v9.0\\\\bin;C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v9.0\\\\libnvvp;C:\\\\WINDOWS\\\\system32;C:\\\\WINDOWS;C:\\\\WINDOWS\\\\System32\\\\Wbem;C:\\\\WINDOWS\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\;C:\\\\Program Files (x86)\\\\Symantec\\\\VIP Access Client\\\\;C:\\\\Program Files\\\\Intel\\\\WiFi\\\\bin\\\\;C:\\\\Program Files\\\\Common Files\\\\Intel\\\\WirelessCommon\\\\;C:\\\\Program Files\\\\Microsoft VS Code\\\\bin;C:\\\\Program Files\\\\Git\\\\cmd;C:\\\\Program Files (x86)\\\\Pandoc\\\\;C:\\\\Program Files (x86)\\\\Graphviz2.38\\\\;C:\\\\Program Files (x86)\\\\Graphviz2.38\\\\bin;C:\\\\Program Files (x86)\\\\Graphviz2.38\\\\bin\\\\dot.exe;C:\\\\Program Files (x86)\\\\NVIDIA Corporation\\\\PhysX\\\\Common;C:\\\\Program Files\\\\Amazon\\\\AWSCLI\\\\bin\\\\;C:\\\\Program Files\\\\nodejs\\\\;C:\\\\Program Files (x86)\\\\Webex\\\\Webex\\\\Applications;C:\\\\Program Files (x86)\\\\Microsoft SQL Server\\\\Client SDK\\\\ODBC\\\\130\\\\Tools\\\\Binn\\\\;C:\\\\Program Files (x86)\\\\Microsoft SQL Server\\\\140\\\\Tools\\\\Binn\\\\;C:\\\\Program Files (x86)\\\\Microsoft SQL Server\\\\140\\\\DTS\\\\Binn\\\\;C:\\\\Program Files (x86)\\\\Microsoft SQL Server\\\\140\\\\Tools\\\\Binn\\\\ManagementStudio\\\\;C:\\\\Users\\\\tbresee\\\\Documents\\\\chromedriver.exe;C:\\\\Users\\\\tbresee\\\\Documents\\\\chromedriver.exe;C:\\\\Program Files\\\\PuTTY\\\\;C:\\\\Program Files\\\\SASHome\\\\SASFoundation\\\\9.4\\\\ets\\\\sasexe;C:\\\\Program Files\\\\SASHome\\\\Secure\\\\ccme4;C:\\\\Program Files\\\\SASHome\\\\x86\\\\Secure\\\\ccme4;C:\\\\Program Files\\\\MySQL\\\\MySQL Utilities 1.6\\\\;C:\\\\SPARK\\\\bin;C:\\\\Users\\\\tbresee\\\\Spark;C:\\\\Program Files (x86)\\\\scala\\\\bin;C:\\\\SPARK\\\\hadoop;C:\\\\HADOOP\\\\hadoop-3.1.2\\\\sbin;C:\\\\SPARK\\\\hadoop;C:\\\\HADOOP\\\\hadoop-2.7.1\\\\bin;C:\\\\SCALA\\\\bin;C:\\\\SPARK\\\\bin;C:\\\\MAVEN\\\\bin;C:\\\\SBT\\\\bin;C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python37\\\\Scripts\\\\;C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python37\\\\;C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps;C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\GitHubDesktop\\\\bin;C:\\\\Program Files (x86)\\\\Graphviz2.38\\\\bin;C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\atom\\\\bin;C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\;C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\Scripts\\\\;C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\Library\\\\bin\\\\;C:\\\\Program Files\\\\Amazon\\\\AWSCLI;C:\\\\Users\\\\tbresee\\\\AppData\\\\Roaming\\\\npm;C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\Programs\\\\MiKTeX 2.9\\\\miktex\\\\bin\\\\x64\\\\;C:\\\\Users\\\\tbresee\\\\Documents\\\\chromedriver.exe;C:\\\\Users\\\\tbresee\\\\Documents\\\\chromedriver.exe;C:\\\\Program Files (x86)\\\\Nmap;C:\\\\SPARK\\\\bin;C:\\\\JAVA\\\\bin;C:\\\\HADOOP\\\\hadoop-2.7.1;C:\\\\HADOOP\\\\hadoop-3.1.2\\\\sbin;C:\\\\SPARK\\\\hadoop;C:\\\\HADOOP\\\\hadoop-2.7.1;C:\\\\HADOOP\\\\hadoop-2.7.1\\\\bin;C:\\\\SCALA\\\\bin;C:\\\\JAVA\\\\bin;C:\\\\SPARK\\\\bin;C:\\\\MAVEN\\\\bin;C:\\\\SCALA\\\\bin;;c:\\\\users\\\\tbresee\\\\appdata\\\\local\\\\programs\\\\python\\\\python37\\\\lib\\\\site-packages\\\\pywin32_system32;c:\\\\users\\\\tbresee\\\\appdata\\\\local\\\\programs\\\\python\\\\python37\\\\lib\\\\site-packages\\\\pywin32_system32;C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\lib\\\\site-packages\\\\pywin32_system32', 'USERPROFILE': 'C:\\\\Users\\\\tbresee', 'SPARK_SCALA_VERSION': '2.12', 'HOMEPATH': '\\\\Users\\\\tbresee', 'NVTOOLSEXT_PATH': 'C:\\\\Program Files\\\\NVIDIA Corporation\\\\NvToolsExt\\\\', 'LOGONSERVER': '\\\\\\\\PRDTDCGSM547', 'SESSIONNAME': 'Console', 'PYTHONHASHSEED': '0', 'MPLBACKEND': 'module://ipykernel.pylab.backend_inline', 'GIT_PAGER': 'cat', 'COMPUTERNAME': 'TM0493322', 'CUDA_PATH_V9_0': 'C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v9.0', 'ASSEMBLY_DIR1': '\"C:\\\\SPARK\\\\assembly\\\\target\\\\scala-2.12\"', 'ONEDRIVE': 'C:\\\\Users\\\\tbresee\\\\OneDrive - T-Mobile USA', 'VBOX_MSI_INSTALL_PATH': 'C:\\\\Program Files\\\\Oracle\\\\VirtualBox\\\\', 'HOMEDRIVE': 'C:', 'PROGRAMFILES': 'C:\\\\Program Files', 'JPY_PARENT_PID': '2112', 'USERDNSDOMAIN': 'GSM1900.ORG', 'SBT_HOME': 'C:\\\\SBT\\\\', 'RUNNER': 'C:\\\\JAVA\\\\bin\\\\java', 'PSMODULEPATH': 'C:\\\\Program Files\\\\WindowsPowerShell\\\\Modules;C:\\\\WINDOWS\\\\system32\\\\WindowsPowerShell\\\\v1.0\\\\Modules;C:\\\\Program Files (x86)\\\\Microsoft Azure Information Protection\\\\Powershell', 'ONEDRIVECOMMERCIAL': 'C:\\\\Users\\\\tbresee\\\\OneDrive - T-Mobile USA', 'SYSTEMROOT': 'C:\\\\WINDOWS', 'CLICOLOR': '1', 'SPARK_HOME': 'C:\\\\SPARK', 'CLASS': 'org.apache.spark.deploy.SparkSubmit', 'TEMP': 'C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\Temp', 'COMMONPROGRAMFILES(X86)': 'C:\\\\Program Files (x86)\\\\Common Files', 'TERM': 'xterm-color', 'USERDOMAIN': 'GSM1900', 'SPARK_CMD': 'set PYSPARK_SUBMIT_ARGS=\"--name\" \"PySparkShell\" \"pyspark-shell\" && jupyter notebook ', 'COMSPEC': 'C:\\\\WINDOWS\\\\system32\\\\cmd.exe', 'NVCUDASAMPLES9_0_ROOT': 'C:\\\\ProgramData\\\\NVIDIA Corporation\\\\CUDA Samples\\\\v9.0', 'USERNAME': 'TBresee', 'MAVEN_HOME': 'C:\\\\MAVEN', '_SPARK_CMD_USAGE': 'Usage: bin\\\\pyspark.cmd [options]', 'SYSTEMDRIVE': 'C:', 'PROGRAMFILES(X86)': 'C:\\\\Program Files (x86)', 'PYTHONPATH': 'C:\\\\SPARK\\\\python\\\\lib\\\\py4j-0.10.7-src.zip;C:\\\\SPARK\\\\python;C:\\\\SPARK\\\\python\\\\lib\\\\py4j;C:\\\\SPARK\\\\python\\\\lib\\\\pyspark', 'PROCESSOR_IDENTIFIER': 'Intel64 Family 6 Model 158 Stepping 9, GenuineIntel', 'PYTHON_RUNNER': 'C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\python', 'PROCESSOR_LEVEL': '6', 'LAUNCHER_OUTPUT': 'C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\Temp\\\\spark-class-launcher-output-21463.txt', 'LOCALAPPDATA': 'C:\\\\Users\\\\tbresee\\\\AppData\\\\Local', 'SPARK_CONF_DIR': 'C:\\\\SPARK\\\\bin\\\\..\\\\conf', 'APPDATA': 'C:\\\\Users\\\\tbresee\\\\AppData\\\\Roaming', 'PATHEXT': '.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC', 'PROGRAMW6432': 'C:\\\\Program Files', 'PYSPARK_DRIVER_PYTHON_OPTS': \"'notebook'\", 'USERDOMAIN_ROAMINGPROFILE': 'GSM1900', 'PAGER': 'cat', 'JAVA_HOME': 'C:\\\\JAVA', '_JAVA_OPTIONS': '-Xmx512M -Xms512M', 'TMP': 'C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\Temp', 'SPARK_ENV_LOADED': '1', 'COMMONPROGRAMFILES': 'C:\\\\Program Files\\\\Common Files', 'PYSPARK_PYTHON': 'C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\python', 'SCALA_HOME': 'C:\\\\SCALA', 'NVCUDASAMPLES_ROOT': 'C:\\\\ProgramData\\\\NVIDIA Corporation\\\\CUDA Samples\\\\v9.0', 'UATDATA': 'C:\\\\WINDOWS\\\\CCM\\\\UATData\\\\D9F8C395-CAB8-491d-B8AC-179A1FE1BE77', 'PROMPT': '$P$G', 'JPY_INTERRUPT_EVENT': '2128', 'LAUNCH_CLASSPATH': '\"C:\\\\SPARK\\\\jars\"\\\\*', 'ADAPTIVACLIENT': 'C:\\\\Program Files (x86)\\\\Adaptiva\\\\AdaptivaClient', 'PYSPARK_DRIVER_PYTHON': 'jupyter', 'FPS_BROWSER_USER_PROFILE_STRING': 'Default', 'ALLUSERSPROFILE': 'C:\\\\ProgramData', 'PROGRAMDATA': 'C:\\\\ProgramData', 'IPY_INTERRUPT_EVENT': '2128', 'CUDA_PATH': 'C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v9.0'})\n"
     ]
    }
   ],
   "source": [
    "print(os.environ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Mapping.values of environ({'ASSEMBLY_DIR2': '\"C:\\\\SPARK\\\\assembly\\\\target\\\\scala-2.11\"', 'QT_DEVICE_PIXEL_RATIO': 'auto', 'PROCESSOR_ARCHITECTURE': 'AMD64', 'HADOOP_HOME': 'C:\\\\HADOOP\\\\hadoop-2.7.1', 'WINDIR': 'C:\\\\WINDOWS', 'OS': 'Windows_NT', 'PROCESSOR_REVISION': '9e09', 'COMMONPROGRAMW6432': 'C:\\\\Program Files\\\\Common Files', 'NUMBER_OF_PROCESSORS': '8', 'PUBLIC': 'C:\\\\Users\\\\Public', 'SPARK_JARS_DIR': '\"C:\\\\SPARK\\\\jars\"', 'PYTHONSTARTUP': 'C:\\\\SPARK\\\\python\\\\pyspark\\\\shell.py', 'FPS_BROWSER_APP_PROFILE_STRING': 'Internet Explorer', 'PYSPARK_SUBMIT_ARGS': '\"--name\" \"PySparkShell\" \"pyspark-shell\" ', 'FIND_SPARK_HOME_PYTHON_SCRIPT': 'C:\\\\SPARK\\\\bin\\\\find_spark_home.py', 'PATH': 'C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\Library\\\\bin;C:\\\\JAVA\\\\bin;C:\\\\ProgramData\\\\DockerDesktop\\\\version-bin;C:\\\\Program Files\\\\Docker\\\\Docker\\\\Resources\\\\bin;C:\\\\Program Files (x86)\\\\Microsoft SDKs\\\\Azure\\\\CLI2\\\\wbin;C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v9.0\\\\bin;C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v9.0\\\\libnvvp;C:\\\\WINDOWS\\\\system32;C:\\\\WINDOWS;C:\\\\WINDOWS\\\\System32\\\\Wbem;C:\\\\WINDOWS\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\;C:\\\\Program Files (x86)\\\\Symantec\\\\VIP Access Client\\\\;C:\\\\Program Files\\\\Intel\\\\WiFi\\\\bin\\\\;C:\\\\Program Files\\\\Common Files\\\\Intel\\\\WirelessCommon\\\\;C:\\\\Program Files\\\\Microsoft VS Code\\\\bin;C:\\\\Program Files\\\\Git\\\\cmd;C:\\\\Program Files (x86)\\\\Pandoc\\\\;C:\\\\Program Files (x86)\\\\Graphviz2.38\\\\;C:\\\\Program Files (x86)\\\\Graphviz2.38\\\\bin;C:\\\\Program Files (x86)\\\\Graphviz2.38\\\\bin\\\\dot.exe;C:\\\\Program Files (x86)\\\\NVIDIA Corporation\\\\PhysX\\\\Common;C:\\\\Program Files\\\\Amazon\\\\AWSCLI\\\\bin\\\\;C:\\\\Program Files\\\\nodejs\\\\;C:\\\\Program Files (x86)\\\\Webex\\\\Webex\\\\Applications;C:\\\\Program Files (x86)\\\\Microsoft SQL Server\\\\Client SDK\\\\ODBC\\\\130\\\\Tools\\\\Binn\\\\;C:\\\\Program Files (x86)\\\\Microsoft SQL Server\\\\140\\\\Tools\\\\Binn\\\\;C:\\\\Program Files (x86)\\\\Microsoft SQL Server\\\\140\\\\DTS\\\\Binn\\\\;C:\\\\Program Files (x86)\\\\Microsoft SQL Server\\\\140\\\\Tools\\\\Binn\\\\ManagementStudio\\\\;C:\\\\Users\\\\tbresee\\\\Documents\\\\chromedriver.exe;C:\\\\Users\\\\tbresee\\\\Documents\\\\chromedriver.exe;C:\\\\Program Files\\\\PuTTY\\\\;C:\\\\Program Files\\\\SASHome\\\\SASFoundation\\\\9.4\\\\ets\\\\sasexe;C:\\\\Program Files\\\\SASHome\\\\Secure\\\\ccme4;C:\\\\Program Files\\\\SASHome\\\\x86\\\\Secure\\\\ccme4;C:\\\\Program Files\\\\MySQL\\\\MySQL Utilities 1.6\\\\;C:\\\\SPARK\\\\bin;C:\\\\Users\\\\tbresee\\\\Spark;C:\\\\Program Files (x86)\\\\scala\\\\bin;C:\\\\SPARK\\\\hadoop;C:\\\\HADOOP\\\\hadoop-3.1.2\\\\sbin;C:\\\\SPARK\\\\hadoop;C:\\\\HADOOP\\\\hadoop-2.7.1\\\\bin;C:\\\\SCALA\\\\bin;C:\\\\SPARK\\\\bin;C:\\\\MAVEN\\\\bin;C:\\\\SBT\\\\bin;C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python37\\\\Scripts\\\\;C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python37\\\\;C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps;C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\GitHubDesktop\\\\bin;C:\\\\Program Files (x86)\\\\Graphviz2.38\\\\bin;C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\atom\\\\bin;C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\;C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\Scripts\\\\;C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\Library\\\\bin\\\\;C:\\\\Program Files\\\\Amazon\\\\AWSCLI;C:\\\\Users\\\\tbresee\\\\AppData\\\\Roaming\\\\npm;C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\Programs\\\\MiKTeX 2.9\\\\miktex\\\\bin\\\\x64\\\\;C:\\\\Users\\\\tbresee\\\\Documents\\\\chromedriver.exe;C:\\\\Users\\\\tbresee\\\\Documents\\\\chromedriver.exe;C:\\\\Program Files (x86)\\\\Nmap;C:\\\\SPARK\\\\bin;C:\\\\JAVA\\\\bin;C:\\\\HADOOP\\\\hadoop-2.7.1;C:\\\\HADOOP\\\\hadoop-3.1.2\\\\sbin;C:\\\\SPARK\\\\hadoop;C:\\\\HADOOP\\\\hadoop-2.7.1;C:\\\\HADOOP\\\\hadoop-2.7.1\\\\bin;C:\\\\SCALA\\\\bin;C:\\\\JAVA\\\\bin;C:\\\\SPARK\\\\bin;C:\\\\MAVEN\\\\bin;C:\\\\SCALA\\\\bin;;c:\\\\users\\\\tbresee\\\\appdata\\\\local\\\\programs\\\\python\\\\python37\\\\lib\\\\site-packages\\\\pywin32_system32;c:\\\\users\\\\tbresee\\\\appdata\\\\local\\\\programs\\\\python\\\\python37\\\\lib\\\\site-packages\\\\pywin32_system32;C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\lib\\\\site-packages\\\\pywin32_system32', 'USERPROFILE': 'C:\\\\Users\\\\tbresee', 'SPARK_SCALA_VERSION': '2.12', 'HOMEPATH': '\\\\Users\\\\tbresee', 'NVTOOLSEXT_PATH': 'C:\\\\Program Files\\\\NVIDIA Corporation\\\\NvToolsExt\\\\', 'LOGONSERVER': '\\\\\\\\PRDTDCGSM547', 'SESSIONNAME': 'Console', 'PYTHONHASHSEED': '0', 'MPLBACKEND': 'module://ipykernel.pylab.backend_inline', 'GIT_PAGER': 'cat', 'COMPUTERNAME': 'TM0493322', 'CUDA_PATH_V9_0': 'C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v9.0', 'ASSEMBLY_DIR1': '\"C:\\\\SPARK\\\\assembly\\\\target\\\\scala-2.12\"', 'ONEDRIVE': 'C:\\\\Users\\\\tbresee\\\\OneDrive - T-Mobile USA', 'VBOX_MSI_INSTALL_PATH': 'C:\\\\Program Files\\\\Oracle\\\\VirtualBox\\\\', 'HOMEDRIVE': 'C:', 'PROGRAMFILES': 'C:\\\\Program Files', 'JPY_PARENT_PID': '2112', 'USERDNSDOMAIN': 'GSM1900.ORG', 'SBT_HOME': 'C:\\\\SBT\\\\', 'RUNNER': 'C:\\\\JAVA\\\\bin\\\\java', 'PSMODULEPATH': 'C:\\\\Program Files\\\\WindowsPowerShell\\\\Modules;C:\\\\WINDOWS\\\\system32\\\\WindowsPowerShell\\\\v1.0\\\\Modules;C:\\\\Program Files (x86)\\\\Microsoft Azure Information Protection\\\\Powershell', 'ONEDRIVECOMMERCIAL': 'C:\\\\Users\\\\tbresee\\\\OneDrive - T-Mobile USA', 'SYSTEMROOT': 'C:\\\\WINDOWS', 'CLICOLOR': '1', 'SPARK_HOME': 'C:\\\\SPARK', 'CLASS': 'org.apache.spark.deploy.SparkSubmit', 'TEMP': 'C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\Temp', 'COMMONPROGRAMFILES(X86)': 'C:\\\\Program Files (x86)\\\\Common Files', 'TERM': 'xterm-color', 'USERDOMAIN': 'GSM1900', 'SPARK_CMD': 'set PYSPARK_SUBMIT_ARGS=\"--name\" \"PySparkShell\" \"pyspark-shell\" && jupyter notebook ', 'COMSPEC': 'C:\\\\WINDOWS\\\\system32\\\\cmd.exe', 'NVCUDASAMPLES9_0_ROOT': 'C:\\\\ProgramData\\\\NVIDIA Corporation\\\\CUDA Samples\\\\v9.0', 'USERNAME': 'TBresee', 'MAVEN_HOME': 'C:\\\\MAVEN', '_SPARK_CMD_USAGE': 'Usage: bin\\\\pyspark.cmd [options]', 'SYSTEMDRIVE': 'C:', 'PROGRAMFILES(X86)': 'C:\\\\Program Files (x86)', 'PYTHONPATH': 'C:\\\\SPARK\\\\python\\\\lib\\\\py4j-0.10.7-src.zip;C:\\\\SPARK\\\\python;C:\\\\SPARK\\\\python\\\\lib\\\\py4j;C:\\\\SPARK\\\\python\\\\lib\\\\pyspark', 'PROCESSOR_IDENTIFIER': 'Intel64 Family 6 Model 158 Stepping 9, GenuineIntel', 'PYTHON_RUNNER': 'C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\python', 'PROCESSOR_LEVEL': '6', 'LAUNCHER_OUTPUT': 'C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\Temp\\\\spark-class-launcher-output-21463.txt', 'LOCALAPPDATA': 'C:\\\\Users\\\\tbresee\\\\AppData\\\\Local', 'SPARK_CONF_DIR': 'C:\\\\SPARK\\\\bin\\\\..\\\\conf', 'APPDATA': 'C:\\\\Users\\\\tbresee\\\\AppData\\\\Roaming', 'PATHEXT': '.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC', 'PROGRAMW6432': 'C:\\\\Program Files', 'PYSPARK_DRIVER_PYTHON_OPTS': \"'notebook'\", 'USERDOMAIN_ROAMINGPROFILE': 'GSM1900', 'PAGER': 'cat', 'JAVA_HOME': 'C:\\\\JAVA', '_JAVA_OPTIONS': '-Xmx512M -Xms512M', 'TMP': 'C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\Temp', 'SPARK_ENV_LOADED': '1', 'COMMONPROGRAMFILES': 'C:\\\\Program Files\\\\Common Files', 'PYSPARK_PYTHON': 'C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\python', 'SCALA_HOME': 'C:\\\\SCALA', 'NVCUDASAMPLES_ROOT': 'C:\\\\ProgramData\\\\NVIDIA Corporation\\\\CUDA Samples\\\\v9.0', 'UATDATA': 'C:\\\\WINDOWS\\\\CCM\\\\UATData\\\\D9F8C395-CAB8-491d-B8AC-179A1FE1BE77', 'PROMPT': '$P$G', 'JPY_INTERRUPT_EVENT': '2128', 'LAUNCH_CLASSPATH': '\"C:\\\\SPARK\\\\jars\"\\\\*', 'ADAPTIVACLIENT': 'C:\\\\Program Files (x86)\\\\Adaptiva\\\\AdaptivaClient', 'PYSPARK_DRIVER_PYTHON': 'jupyter', 'FPS_BROWSER_USER_PROFILE_STRING': 'Default', 'ALLUSERSPROFILE': 'C:\\\\ProgramData', 'PROGRAMDATA': 'C:\\\\ProgramData', 'IPY_INTERRUPT_EVENT': '2128', 'CUDA_PATH': 'C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v9.0'})>\n"
     ]
    }
   ],
   "source": [
    "print(os.environ.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "environ{'ADAPTIVACLIENT': 'C:\\\\Program Files (x86)\\\\Adaptiva\\\\AdaptivaClient',\n",
       "        'ALLUSERSPROFILE': 'C:\\\\ProgramData',\n",
       "        'APPDATA': 'C:\\\\Users\\\\tbresee\\\\AppData\\\\Roaming',\n",
       "        'ASSEMBLY_DIR1': '\"C:\\\\SPARK\\\\assembly\\\\target\\\\scala-2.12\"',\n",
       "        'ASSEMBLY_DIR2': '\"C:\\\\SPARK\\\\assembly\\\\target\\\\scala-2.11\"',\n",
       "        'CLASS': 'org.apache.spark.deploy.SparkSubmit',\n",
       "        'CLICOLOR': '1',\n",
       "        'COMMONPROGRAMFILES': 'C:\\\\Program Files\\\\Common Files',\n",
       "        'COMMONPROGRAMFILES(X86)': 'C:\\\\Program Files (x86)\\\\Common Files',\n",
       "        'COMMONPROGRAMW6432': 'C:\\\\Program Files\\\\Common Files',\n",
       "        'COMPUTERNAME': 'TM0493322',\n",
       "        'COMSPEC': 'C:\\\\WINDOWS\\\\system32\\\\cmd.exe',\n",
       "        'CUDA_PATH': 'C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v9.0',\n",
       "        'CUDA_PATH_V9_0': 'C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v9.0',\n",
       "        'FIND_SPARK_HOME_PYTHON_SCRIPT': 'C:\\\\SPARK\\\\bin\\\\find_spark_home.py',\n",
       "        'FPS_BROWSER_APP_PROFILE_STRING': 'Internet Explorer',\n",
       "        'FPS_BROWSER_USER_PROFILE_STRING': 'Default',\n",
       "        'GIT_PAGER': 'cat',\n",
       "        'HADOOP_HOME': 'C:\\\\HADOOP\\\\hadoop-2.7.1',\n",
       "        'HOMEDRIVE': 'C:',\n",
       "        'HOMEPATH': '\\\\Users\\\\tbresee',\n",
       "        'IPY_INTERRUPT_EVENT': '2128',\n",
       "        'JAVA_HOME': 'C:\\\\JAVA',\n",
       "        'JPY_INTERRUPT_EVENT': '2128',\n",
       "        'JPY_PARENT_PID': '2112',\n",
       "        'LAUNCHER_OUTPUT': 'C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\Temp\\\\spark-class-launcher-output-21463.txt',\n",
       "        'LAUNCH_CLASSPATH': '\"C:\\\\SPARK\\\\jars\"\\\\*',\n",
       "        'LOCALAPPDATA': 'C:\\\\Users\\\\tbresee\\\\AppData\\\\Local',\n",
       "        'LOGONSERVER': '\\\\\\\\PRDTDCGSM547',\n",
       "        'MAVEN_HOME': 'C:\\\\MAVEN',\n",
       "        'MPLBACKEND': 'module://ipykernel.pylab.backend_inline',\n",
       "        'NUMBER_OF_PROCESSORS': '8',\n",
       "        'NVCUDASAMPLES9_0_ROOT': 'C:\\\\ProgramData\\\\NVIDIA Corporation\\\\CUDA Samples\\\\v9.0',\n",
       "        'NVCUDASAMPLES_ROOT': 'C:\\\\ProgramData\\\\NVIDIA Corporation\\\\CUDA Samples\\\\v9.0',\n",
       "        'NVTOOLSEXT_PATH': 'C:\\\\Program Files\\\\NVIDIA Corporation\\\\NvToolsExt\\\\',\n",
       "        'ONEDRIVE': 'C:\\\\Users\\\\tbresee\\\\OneDrive - T-Mobile USA',\n",
       "        'ONEDRIVECOMMERCIAL': 'C:\\\\Users\\\\tbresee\\\\OneDrive - T-Mobile USA',\n",
       "        'OS': 'Windows_NT',\n",
       "        'PAGER': 'cat',\n",
       "        'PATH': 'C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\Library\\\\bin;C:\\\\JAVA\\\\bin;C:\\\\ProgramData\\\\DockerDesktop\\\\version-bin;C:\\\\Program Files\\\\Docker\\\\Docker\\\\Resources\\\\bin;C:\\\\Program Files (x86)\\\\Microsoft SDKs\\\\Azure\\\\CLI2\\\\wbin;C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v9.0\\\\bin;C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v9.0\\\\libnvvp;C:\\\\WINDOWS\\\\system32;C:\\\\WINDOWS;C:\\\\WINDOWS\\\\System32\\\\Wbem;C:\\\\WINDOWS\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\;C:\\\\Program Files (x86)\\\\Symantec\\\\VIP Access Client\\\\;C:\\\\Program Files\\\\Intel\\\\WiFi\\\\bin\\\\;C:\\\\Program Files\\\\Common Files\\\\Intel\\\\WirelessCommon\\\\;C:\\\\Program Files\\\\Microsoft VS Code\\\\bin;C:\\\\Program Files\\\\Git\\\\cmd;C:\\\\Program Files (x86)\\\\Pandoc\\\\;C:\\\\Program Files (x86)\\\\Graphviz2.38\\\\;C:\\\\Program Files (x86)\\\\Graphviz2.38\\\\bin;C:\\\\Program Files (x86)\\\\Graphviz2.38\\\\bin\\\\dot.exe;C:\\\\Program Files (x86)\\\\NVIDIA Corporation\\\\PhysX\\\\Common;C:\\\\Program Files\\\\Amazon\\\\AWSCLI\\\\bin\\\\;C:\\\\Program Files\\\\nodejs\\\\;C:\\\\Program Files (x86)\\\\Webex\\\\Webex\\\\Applications;C:\\\\Program Files (x86)\\\\Microsoft SQL Server\\\\Client SDK\\\\ODBC\\\\130\\\\Tools\\\\Binn\\\\;C:\\\\Program Files (x86)\\\\Microsoft SQL Server\\\\140\\\\Tools\\\\Binn\\\\;C:\\\\Program Files (x86)\\\\Microsoft SQL Server\\\\140\\\\DTS\\\\Binn\\\\;C:\\\\Program Files (x86)\\\\Microsoft SQL Server\\\\140\\\\Tools\\\\Binn\\\\ManagementStudio\\\\;C:\\\\Users\\\\tbresee\\\\Documents\\\\chromedriver.exe;C:\\\\Users\\\\tbresee\\\\Documents\\\\chromedriver.exe;C:\\\\Program Files\\\\PuTTY\\\\;C:\\\\Program Files\\\\SASHome\\\\SASFoundation\\\\9.4\\\\ets\\\\sasexe;C:\\\\Program Files\\\\SASHome\\\\Secure\\\\ccme4;C:\\\\Program Files\\\\SASHome\\\\x86\\\\Secure\\\\ccme4;C:\\\\Program Files\\\\MySQL\\\\MySQL Utilities 1.6\\\\;C:\\\\SPARK\\\\bin;C:\\\\Users\\\\tbresee\\\\Spark;C:\\\\Program Files (x86)\\\\scala\\\\bin;C:\\\\SPARK\\\\hadoop;C:\\\\HADOOP\\\\hadoop-3.1.2\\\\sbin;C:\\\\SPARK\\\\hadoop;C:\\\\HADOOP\\\\hadoop-2.7.1\\\\bin;C:\\\\SCALA\\\\bin;C:\\\\SPARK\\\\bin;C:\\\\MAVEN\\\\bin;C:\\\\SBT\\\\bin;C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python37\\\\Scripts\\\\;C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python37\\\\;C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps;C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\GitHubDesktop\\\\bin;C:\\\\Program Files (x86)\\\\Graphviz2.38\\\\bin;C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\atom\\\\bin;C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\;C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\Scripts\\\\;C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\Library\\\\bin\\\\;C:\\\\Program Files\\\\Amazon\\\\AWSCLI;C:\\\\Users\\\\tbresee\\\\AppData\\\\Roaming\\\\npm;C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\Programs\\\\MiKTeX 2.9\\\\miktex\\\\bin\\\\x64\\\\;C:\\\\Users\\\\tbresee\\\\Documents\\\\chromedriver.exe;C:\\\\Users\\\\tbresee\\\\Documents\\\\chromedriver.exe;C:\\\\Program Files (x86)\\\\Nmap;C:\\\\SPARK\\\\bin;C:\\\\JAVA\\\\bin;C:\\\\HADOOP\\\\hadoop-2.7.1;C:\\\\HADOOP\\\\hadoop-3.1.2\\\\sbin;C:\\\\SPARK\\\\hadoop;C:\\\\HADOOP\\\\hadoop-2.7.1;C:\\\\HADOOP\\\\hadoop-2.7.1\\\\bin;C:\\\\SCALA\\\\bin;C:\\\\JAVA\\\\bin;C:\\\\SPARK\\\\bin;C:\\\\MAVEN\\\\bin;C:\\\\SCALA\\\\bin;;c:\\\\users\\\\tbresee\\\\appdata\\\\local\\\\programs\\\\python\\\\python37\\\\lib\\\\site-packages\\\\pywin32_system32;c:\\\\users\\\\tbresee\\\\appdata\\\\local\\\\programs\\\\python\\\\python37\\\\lib\\\\site-packages\\\\pywin32_system32;C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\lib\\\\site-packages\\\\pywin32_system32',\n",
       "        'PATHEXT': '.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC',\n",
       "        'PROCESSOR_ARCHITECTURE': 'AMD64',\n",
       "        'PROCESSOR_IDENTIFIER': 'Intel64 Family 6 Model 158 Stepping 9, GenuineIntel',\n",
       "        'PROCESSOR_LEVEL': '6',\n",
       "        'PROCESSOR_REVISION': '9e09',\n",
       "        'PROGRAMDATA': 'C:\\\\ProgramData',\n",
       "        'PROGRAMFILES': 'C:\\\\Program Files',\n",
       "        'PROGRAMFILES(X86)': 'C:\\\\Program Files (x86)',\n",
       "        'PROGRAMW6432': 'C:\\\\Program Files',\n",
       "        'PROMPT': '$P$G',\n",
       "        'PSMODULEPATH': 'C:\\\\Program Files\\\\WindowsPowerShell\\\\Modules;C:\\\\WINDOWS\\\\system32\\\\WindowsPowerShell\\\\v1.0\\\\Modules;C:\\\\Program Files (x86)\\\\Microsoft Azure Information Protection\\\\Powershell',\n",
       "        'PUBLIC': 'C:\\\\Users\\\\Public',\n",
       "        'PYSPARK_DRIVER_PYTHON': 'jupyter',\n",
       "        'PYSPARK_DRIVER_PYTHON_OPTS': \"'notebook'\",\n",
       "        'PYSPARK_PYTHON': 'C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\python',\n",
       "        'PYSPARK_SUBMIT_ARGS': '\"--name\" \"PySparkShell\" \"pyspark-shell\" ',\n",
       "        'PYTHONHASHSEED': '0',\n",
       "        'PYTHONPATH': 'C:\\\\SPARK\\\\python\\\\lib\\\\py4j-0.10.7-src.zip;C:\\\\SPARK\\\\python;C:\\\\SPARK\\\\python\\\\lib\\\\py4j;C:\\\\SPARK\\\\python\\\\lib\\\\pyspark',\n",
       "        'PYTHONSTARTUP': 'C:\\\\SPARK\\\\python\\\\pyspark\\\\shell.py',\n",
       "        'PYTHON_RUNNER': 'C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\python',\n",
       "        'QT_DEVICE_PIXEL_RATIO': 'auto',\n",
       "        'RUNNER': 'C:\\\\JAVA\\\\bin\\\\java',\n",
       "        'SBT_HOME': 'C:\\\\SBT\\\\',\n",
       "        'SCALA_HOME': 'C:\\\\SCALA',\n",
       "        'SESSIONNAME': 'Console',\n",
       "        'SPARK_CMD': 'set PYSPARK_SUBMIT_ARGS=\"--name\" \"PySparkShell\" \"pyspark-shell\" && jupyter notebook ',\n",
       "        'SPARK_CONF_DIR': 'C:\\\\SPARK\\\\bin\\\\..\\\\conf',\n",
       "        'SPARK_ENV_LOADED': '1',\n",
       "        'SPARK_HOME': 'C:\\\\SPARK',\n",
       "        'SPARK_JARS_DIR': '\"C:\\\\SPARK\\\\jars\"',\n",
       "        'SPARK_SCALA_VERSION': '2.12',\n",
       "        'SYSTEMDRIVE': 'C:',\n",
       "        'SYSTEMROOT': 'C:\\\\WINDOWS',\n",
       "        'TEMP': 'C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\Temp',\n",
       "        'TERM': 'xterm-color',\n",
       "        'TMP': 'C:\\\\Users\\\\tbresee\\\\AppData\\\\Local\\\\Temp',\n",
       "        'UATDATA': 'C:\\\\WINDOWS\\\\CCM\\\\UATData\\\\D9F8C395-CAB8-491d-B8AC-179A1FE1BE77',\n",
       "        'USERDNSDOMAIN': 'GSM1900.ORG',\n",
       "        'USERDOMAIN': 'GSM1900',\n",
       "        'USERDOMAIN_ROAMINGPROFILE': 'GSM1900',\n",
       "        'USERNAME': 'TBresee',\n",
       "        'USERPROFILE': 'C:\\\\Users\\\\tbresee',\n",
       "        'VBOX_MSI_INSTALL_PATH': 'C:\\\\Program Files\\\\Oracle\\\\VirtualBox\\\\',\n",
       "        'WINDIR': 'C:\\\\WINDOWS',\n",
       "        '_JAVA_OPTIONS': '-Xmx512M -Xms512M',\n",
       "        '_SPARK_CMD_USAGE': 'Usage: bin\\\\pyspark.cmd [options]'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LIST ALL ENV VARIABLES:\n",
    "\n",
    "os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASSEMBLY_DIR2: \"C:\\SPARK\\assembly\\target\\scala-2.11\"\n",
      "QT_DEVICE_PIXEL_RATIO: auto\n",
      "PROCESSOR_ARCHITECTURE: AMD64\n",
      "HADOOP_HOME: C:\\HADOOP\\hadoop-2.7.1\n",
      "WINDIR: C:\\WINDOWS\n",
      "OS: Windows_NT\n",
      "PROCESSOR_REVISION: 9e09\n",
      "COMMONPROGRAMW6432: C:\\Program Files\\Common Files\n",
      "NUMBER_OF_PROCESSORS: 8\n",
      "PUBLIC: C:\\Users\\Public\n",
      "SPARK_JARS_DIR: \"C:\\SPARK\\jars\"\n",
      "PYTHONSTARTUP: C:\\SPARK\\python\\pyspark\\shell.py\n",
      "FPS_BROWSER_APP_PROFILE_STRING: Internet Explorer\n",
      "PYSPARK_SUBMIT_ARGS: \"--name\" \"PySparkShell\" \"pyspark-shell\" \n",
      "FIND_SPARK_HOME_PYTHON_SCRIPT: C:\\SPARK\\bin\\find_spark_home.py\n",
      "PATH: C:\\Users\\tbresee\\AppData\\Local\\Continuum\\anaconda3\\Library\\bin;C:\\JAVA\\bin;C:\\ProgramData\\DockerDesktop\\version-bin;C:\\Program Files\\Docker\\Docker\\Resources\\bin;C:\\Program Files (x86)\\Microsoft SDKs\\Azure\\CLI2\\wbin;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\bin;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\libnvvp;C:\\WINDOWS\\system32;C:\\WINDOWS;C:\\WINDOWS\\System32\\Wbem;C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\;C:\\Program Files (x86)\\Symantec\\VIP Access Client\\;C:\\Program Files\\Intel\\WiFi\\bin\\;C:\\Program Files\\Common Files\\Intel\\WirelessCommon\\;C:\\Program Files\\Microsoft VS Code\\bin;C:\\Program Files\\Git\\cmd;C:\\Program Files (x86)\\Pandoc\\;C:\\Program Files (x86)\\Graphviz2.38\\;C:\\Program Files (x86)\\Graphviz2.38\\bin;C:\\Program Files (x86)\\Graphviz2.38\\bin\\dot.exe;C:\\Program Files (x86)\\NVIDIA Corporation\\PhysX\\Common;C:\\Program Files\\Amazon\\AWSCLI\\bin\\;C:\\Program Files\\nodejs\\;C:\\Program Files (x86)\\Webex\\Webex\\Applications;C:\\Program Files (x86)\\Microsoft SQL Server\\Client SDK\\ODBC\\130\\Tools\\Binn\\;C:\\Program Files (x86)\\Microsoft SQL Server\\140\\Tools\\Binn\\;C:\\Program Files (x86)\\Microsoft SQL Server\\140\\DTS\\Binn\\;C:\\Program Files (x86)\\Microsoft SQL Server\\140\\Tools\\Binn\\ManagementStudio\\;C:\\Users\\tbresee\\Documents\\chromedriver.exe;C:\\Users\\tbresee\\Documents\\chromedriver.exe;C:\\Program Files\\PuTTY\\;C:\\Program Files\\SASHome\\SASFoundation\\9.4\\ets\\sasexe;C:\\Program Files\\SASHome\\Secure\\ccme4;C:\\Program Files\\SASHome\\x86\\Secure\\ccme4;C:\\Program Files\\MySQL\\MySQL Utilities 1.6\\;C:\\SPARK\\bin;C:\\Users\\tbresee\\Spark;C:\\Program Files (x86)\\scala\\bin;C:\\SPARK\\hadoop;C:\\HADOOP\\hadoop-3.1.2\\sbin;C:\\SPARK\\hadoop;C:\\HADOOP\\hadoop-2.7.1\\bin;C:\\SCALA\\bin;C:\\SPARK\\bin;C:\\MAVEN\\bin;C:\\SBT\\bin;C:\\Users\\tbresee\\AppData\\Local\\Programs\\Python\\Python37\\Scripts\\;C:\\Users\\tbresee\\AppData\\Local\\Programs\\Python\\Python37\\;C:\\Users\\tbresee\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Users\\tbresee\\AppData\\Local\\GitHubDesktop\\bin;C:\\Program Files (x86)\\Graphviz2.38\\bin;C:\\Users\\tbresee\\AppData\\Local\\atom\\bin;C:\\Users\\tbresee\\AppData\\Local\\Continuum\\anaconda3\\;C:\\Users\\tbresee\\AppData\\Local\\Continuum\\anaconda3\\Scripts\\;C:\\Users\\tbresee\\AppData\\Local\\Continuum\\anaconda3\\Library\\bin\\;C:\\Program Files\\Amazon\\AWSCLI;C:\\Users\\tbresee\\AppData\\Roaming\\npm;C:\\Users\\tbresee\\AppData\\Local\\Programs\\MiKTeX 2.9\\miktex\\bin\\x64\\;C:\\Users\\tbresee\\Documents\\chromedriver.exe;C:\\Users\\tbresee\\Documents\\chromedriver.exe;C:\\Program Files (x86)\\Nmap;C:\\SPARK\\bin;C:\\JAVA\\bin;C:\\HADOOP\\hadoop-2.7.1;C:\\HADOOP\\hadoop-3.1.2\\sbin;C:\\SPARK\\hadoop;C:\\HADOOP\\hadoop-2.7.1;C:\\HADOOP\\hadoop-2.7.1\\bin;C:\\SCALA\\bin;C:\\JAVA\\bin;C:\\SPARK\\bin;C:\\MAVEN\\bin;C:\\SCALA\\bin;;c:\\users\\tbresee\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pywin32_system32;c:\\users\\tbresee\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pywin32_system32;C:\\Users\\tbresee\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pywin32_system32\n",
      "USERPROFILE: C:\\Users\\tbresee\n",
      "SPARK_SCALA_VERSION: 2.12\n",
      "HOMEPATH: \\Users\\tbresee\n",
      "NVTOOLSEXT_PATH: C:\\Program Files\\NVIDIA Corporation\\NvToolsExt\\\n",
      "LOGONSERVER: \\\\PRDTDCGSM547\n",
      "SESSIONNAME: Console\n",
      "PYTHONHASHSEED: 0\n",
      "MPLBACKEND: module://ipykernel.pylab.backend_inline\n",
      "GIT_PAGER: cat\n",
      "COMPUTERNAME: TM0493322\n",
      "CUDA_PATH_V9_0: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\n",
      "ASSEMBLY_DIR1: \"C:\\SPARK\\assembly\\target\\scala-2.12\"\n",
      "ONEDRIVE: C:\\Users\\tbresee\\OneDrive - T-Mobile USA\n",
      "VBOX_MSI_INSTALL_PATH: C:\\Program Files\\Oracle\\VirtualBox\\\n",
      "HOMEDRIVE: C:\n",
      "PROGRAMFILES: C:\\Program Files\n",
      "JPY_PARENT_PID: 2112\n",
      "USERDNSDOMAIN: GSM1900.ORG\n",
      "SBT_HOME: C:\\SBT\\\n",
      "RUNNER: C:\\JAVA\\bin\\java\n",
      "PSMODULEPATH: C:\\Program Files\\WindowsPowerShell\\Modules;C:\\WINDOWS\\system32\\WindowsPowerShell\\v1.0\\Modules;C:\\Program Files (x86)\\Microsoft Azure Information Protection\\Powershell\n",
      "ONEDRIVECOMMERCIAL: C:\\Users\\tbresee\\OneDrive - T-Mobile USA\n",
      "SYSTEMROOT: C:\\WINDOWS\n",
      "CLICOLOR: 1\n",
      "SPARK_HOME: C:\\SPARK\n",
      "CLASS: org.apache.spark.deploy.SparkSubmit\n",
      "TEMP: C:\\Users\\tbresee\\AppData\\Local\\Temp\n",
      "COMMONPROGRAMFILES(X86): C:\\Program Files (x86)\\Common Files\n",
      "TERM: xterm-color\n",
      "USERDOMAIN: GSM1900\n",
      "SPARK_CMD: set PYSPARK_SUBMIT_ARGS=\"--name\" \"PySparkShell\" \"pyspark-shell\" && jupyter notebook \n",
      "COMSPEC: C:\\WINDOWS\\system32\\cmd.exe\n",
      "NVCUDASAMPLES9_0_ROOT: C:\\ProgramData\\NVIDIA Corporation\\CUDA Samples\\v9.0\n",
      "USERNAME: TBresee\n",
      "MAVEN_HOME: C:\\MAVEN\n",
      "_SPARK_CMD_USAGE: Usage: bin\\pyspark.cmd [options]\n",
      "SYSTEMDRIVE: C:\n",
      "PROGRAMFILES(X86): C:\\Program Files (x86)\n",
      "PYTHONPATH: C:\\SPARK\\python\\lib\\py4j-0.10.7-src.zip;C:\\SPARK\\python;C:\\SPARK\\python\\lib\\py4j;C:\\SPARK\\python\\lib\\pyspark\n",
      "PROCESSOR_IDENTIFIER: Intel64 Family 6 Model 158 Stepping 9, GenuineIntel\n",
      "PYTHON_RUNNER: C:\\Users\\tbresee\\AppData\\Local\\Continuum\\anaconda3\\python\n",
      "PROCESSOR_LEVEL: 6\n",
      "LAUNCHER_OUTPUT: C:\\Users\\tbresee\\AppData\\Local\\Temp\\spark-class-launcher-output-21463.txt\n",
      "LOCALAPPDATA: C:\\Users\\tbresee\\AppData\\Local\n",
      "SPARK_CONF_DIR: C:\\SPARK\\bin\\..\\conf\n",
      "APPDATA: C:\\Users\\tbresee\\AppData\\Roaming\n",
      "PATHEXT: .COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC\n",
      "PROGRAMW6432: C:\\Program Files\n",
      "PYSPARK_DRIVER_PYTHON_OPTS: 'notebook'\n",
      "USERDOMAIN_ROAMINGPROFILE: GSM1900\n",
      "PAGER: cat\n",
      "JAVA_HOME: C:\\JAVA\n",
      "_JAVA_OPTIONS: -Xmx512M -Xms512M\n",
      "TMP: C:\\Users\\tbresee\\AppData\\Local\\Temp\n",
      "SPARK_ENV_LOADED: 1\n",
      "COMMONPROGRAMFILES: C:\\Program Files\\Common Files\n",
      "PYSPARK_PYTHON: C:\\Users\\tbresee\\AppData\\Local\\Continuum\\anaconda3\\python\n",
      "SCALA_HOME: C:\\SCALA\n",
      "NVCUDASAMPLES_ROOT: C:\\ProgramData\\NVIDIA Corporation\\CUDA Samples\\v9.0\n",
      "UATDATA: C:\\WINDOWS\\CCM\\UATData\\D9F8C395-CAB8-491d-B8AC-179A1FE1BE77\n",
      "PROMPT: $P$G\n",
      "JPY_INTERRUPT_EVENT: 2128\n",
      "LAUNCH_CLASSPATH: \"C:\\SPARK\\jars\"\\*\n",
      "ADAPTIVACLIENT: C:\\Program Files (x86)\\Adaptiva\\AdaptivaClient\n",
      "PYSPARK_DRIVER_PYTHON: jupyter\n",
      "FPS_BROWSER_USER_PROFILE_STRING: Default\n",
      "ALLUSERSPROFILE: C:\\ProgramData\n",
      "PROGRAMDATA: C:\\ProgramData\n",
      "IPY_INTERRUPT_EVENT: 2128\n",
      "CUDA_PATH: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# PRINT OUT ALL THE ENVIRONMENT VARIABLES \n",
    "\n",
    "import os\n",
    "for item, value in os.environ.items():\n",
    "    print('{}: {}'.format(item, value))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\JAVA\n"
     ]
    }
   ],
   "source": [
    "print(os.environ.get('JAVA_HOME'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:  \n",
    "#    env_value = os.environ.get(\"JAVA_HOME\")\n",
    "# except KeyError: \n",
    "#    print(\"Not exist environment value for %s\" % \"key_maybe_not_exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'JAVA_HOME' in os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\JAVA\n",
      "C:\\SPARK\n",
      "C:\\HADOOP\\hadoop-2.7.1\n",
      "jupyter\n",
      "'notebook'\n",
      "C:\\SPARK\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(os.environ['JAVA_HOME'])\n",
    "print(os.environ['SPARK_HOME'])\n",
    "print(os.environ['HADOOP_HOME'])\n",
    "print(os.environ['PYSPARK_DRIVER_PYTHON'])\n",
    "print(os.environ['PYSPARK_DRIVER_PYTHON_OPTS'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Python version is 3.5.5\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"The Python version is %s.%s.%s\" % sys.version_info[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.5\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "print(platform.python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.5 | packaged by conda-forge | (default, Jul 24 2018, 01:52:17) [MSC v.1900 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print (sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "openjdk version \"1.8.0_152-release\"\n",
      "OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12)\n",
      "OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode)\n",
      "Picked up _JAVA_OPTIONS: -Xmx512M -Xms512M\n"
     ]
    }
   ],
   "source": [
    "!java -version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct Launching Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://TM0493322.gsm1900.org:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x23c696b8978>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark  # why does this say hive ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://TM0493322.gsm1900.org:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i think by launching this, that sc already existed ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://TM0493322.gsm1900.org:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x23c696b8978>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "\n",
    "1.  Existing env variables\n",
    "\n",
    "export PYSPARK_DRIVER_PYTHON=jupyter\n",
    "\n",
    "export PYSPARK_DRIVER_PYTHON_OPTS='notebook'\n",
    "\n",
    "Restart your terminal and launch PySpark again:\n",
    "\n",
    "\n",
    "\n",
    "---  java version  ---\n",
    "\n",
    "C:\\SPARK\\python\\pyspark>java -version\n",
    "Picked up _JAVA_OPTIONS: -Xmx512M -Xms512M\n",
    "java version \"1.8.0_211\"\n",
    "Java(TM) SE Runtime Environment (build 1.8.0_211-b12)\n",
    "Java HotSpot(TM) 64-Bit Server VM (build 25.211-b12, mixed mode)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "2.  jupyter kernel locations\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "3.  example of pyspark via windows cmd working\n",
    "\n",
    "\n",
    "C:\\SPARK\\bin>pyspark\n",
    "Picked up _JAVA_OPTIONS: -Xmx512M -Xms512M\n",
    "[I 18:26:30.557 NotebookApp] The port 8888 is already in use, trying another port.\n",
    "[W 18:26:30.625 NotebookApp] Terminals not available (error was No module named 'winpty.cywinpty')\n",
    "[I 18:26:30.793 NotebookApp] Loading IPython parallel extension\n",
    "[I 18:26:30.928 NotebookApp] [jupyter_nbextensions_configurator] enabled 0.4.1\n",
    "[I 18:26:31.583 NotebookApp] Jupyter-Spark enabled!\n",
    "[I 18:26:31.775 NotebookApp] JupyterLab extension loaded from C:\\Users\\tbresee\\AppData\\Roaming\\Python\\Python37\\site-packages\\jupyterlab\n",
    "[I 18:26:31.776 NotebookApp] JupyterLab application directory is C:\\Users\\tbresee\\AppData\\Roaming\\Python\\share\\jupyter\\lab\n",
    "SPARKMONITOR_SERVER: Loading Server Extension\n",
    "[I 18:26:31.815 NotebookApp] Serving notebooks from local directory: C:\\SPARK\\bin\n",
    "[I 18:26:31.817 NotebookApp] The Jupyter Notebook is running at:\n",
    "[I 18:26:31.821 NotebookApp] http://localhost:8889/?token=152b6ac95807db02750d0a2e12bb2d2dcfcfd926b0e3f76c\n",
    "[I 18:26:31.824 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\n",
    "[C 18:26:32.559 NotebookApp]\n",
    "\n",
    "    Copy/paste this URL into your browser when you connect for the first time,\n",
    "    to login with a token:\n",
    "        http://localhost:8889/?token=152b6ac95807db02750d0a2e12bb2d2dcfcfd926b0e3f76c\n",
    "[I 18:26:33.756 NotebookApp] Accepting one-time-token-authenticated connection from ::1\n",
    "[I 18:26:42.861 NotebookApp] Creating new notebook in\n",
    "[I 18:26:44.673 NotebookApp] Kernel started: f4fdaa35-8cd0-4345-a32c-7c093dd4750f\n",
    "[W 18:26:45.057 NotebookApp] 404 GET /nbextensions/sparkmonitor/module.js?v=20190610182628 (::1) 9.02ms referer=http://localhost:8889/notebooks/Untitled.ipynb?kernel_name=python3\n",
    "[W 18:26:45.064 NotebookApp] 404 GET /nbextensions/plotlywidget/extension.js?v=20190610182628 (::1) 4.01ms referer=http://localhost:8889/notebooks/Untitled.ipynb?kernel_name=python3\n",
    "[W 18:26:45.125 NotebookApp] 404 GET /notebooks/nbextensions/c:/Users/tbresee?v=20190610182628 (::1): nbextensions/c:/Users/tbresee is outside root contents directory\n",
    "[W 18:26:45.127 NotebookApp] 404 GET /notebooks/nbextensions/c:/Users/tbresee?v=20190610182628 (::1) 3.01ms referer=http://localhost:8889/notebooks/Untitled.ipynb?kernel_name=python3\n",
    "[W 18:26:45.261 NotebookApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20190610182628 (::1) 5.01ms referer=http://localhost:8889/notebooks/Untitled.ipynb?kernel_name=python3\n",
    "Picked up _JAVA_OPTIONS: -Xmx512M -Xms512M\n",
    "Picked up _JAVA_OPTIONS: -Xmx512M -Xms512M\n",
    "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
    "Setting default log level to \"WARN\".\n",
    "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
    "[I 18:27:00.522 NotebookApp] Adapting to protocol v5.1 for kernel f4fdaa35-8cd0-4345-a32c-7c093dd4750f\n",
    "\n",
    "\n",
    "once i have done this, then i just open up any random blank notebook, and then it all works when i have this configured:\n",
    "\n",
    "\n",
    "\n",
    "---  works  ---\n",
    "\n",
    "import atexit\n",
    "import os\n",
    "import platform\n",
    "import warnings\n",
    "\n",
    "import py4j\n",
    "\n",
    "from pyspark import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "\n",
    "# goldenmonkey turn up \n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---  read this TOM  ---\n",
    "\n",
    "\tits possible you need to launch jupyter notebook FROM the cd spark folder directly with pyspark\n",
    "\t\n",
    "\tSparkSession, without explicitly creating SparkConf, SparkContext or SQLContext, encapsulates them within itself.\n",
    "\n",
    "\tAlso SparkSession has merged SQLContext and HiveContext in one object in Spark 2.0.\n",
    "\n",
    "\n",
    "\n",
    "\tSparkSession, without explicitly creating SparkConf, SparkContext or SQLContext, encapsulates them within itself.\n",
    "\n",
    "\tAlso SparkSession has merged SQLContext and HiveContext in one object in Spark 2.0.\n",
    "\n",
    "\tWhen building a session object, for example:\n",
    "\n",
    "\tval spark = SparkSession .builder() .appName( \"SparkSessionZipsExample\" ) .config( \"spark.sql.warehouse.dir\" , warehouseLocation) .enableHiveSupport() .getOrCreate()\n",
    "\n",
    "\t.enableHiveSupport() provides HiveContext functions. So you're able to use catalog functions since spark has provided connectivity to hive metastore on doing .enableHiveSupport()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "4.  apache spark \n",
    "\n",
    "\n",
    "spark.sql(\"select * from databasename.data\").show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "5.  docker\n",
    "\n",
    "docker run -d -p 8888:8888 jupyter/all-spark-notebook\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "6.  scala\n",
    "\n",
    "val spark = SparkSession\n",
    "  .builder()\n",
    "  .appName(\"Spark Hive Example\")\n",
    "  .config(\"spark.sql.warehouse.dir\", warehouseLocation)\n",
    "  .enableHiveSupport()\n",
    "  .getOrCreate()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "C:\\SPARK\\python\\pyspark>scala -version\n",
    "Picked up _JAVA_OPTIONS: -Xmx512M -Xms512M\n",
    "Scala code runner version 2.12.8 -- Copyright 2002-2018, LAMP/EPFL and Lightbend, Inc.\n",
    "\n",
    "\n",
    "HiveContext is your gateway to Hive. HiveContext has all the functionalities of a SQLContext. In fact, if you look at the API documentation you can see that HiveContext extends SQLContext, meaning, it has support the functionalities that SQLContext support plus more (Hive specific functionalities)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
