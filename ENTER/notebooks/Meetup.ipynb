{"cells":[{"cell_type":"markdown","source":["## Dataframe Basics"],"metadata":{}},{"cell_type":"markdown","source":["### Let's create two DataFrames one as a Dimension and the other one as a Fact."],"metadata":{}},{"cell_type":"code","source":["personDIM = [\n  (123, 'John', 25),\n  (234, 'Doe', 27),\n  (345, 'Jane', 21),\n  (456, 'Jimmy', 45),\n]\n\ntransFact = [\n  (1, 123, 'Soap', 5.00, '2018-01-01'),\n  (2, 123 , 'Fruit', 4.67, '2018-01-01'),\n  (3, 234 , 'Soap', 5.00, '2018-02-01'),\n  (4, 234 , 'Bread', 1.99, '2018-03-01'),\n  (5, 234, 'Milk', 4.55, '2018-08-01'),\n  (6, 345 , 'Chips', 5.99, '2018-09-01'),\n]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["personDF = spark.createDataFrame(personDIM, [\"id\", \"name\", \"age\"])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["transDF = spark.createDataFrame(transFact, [\"id\", \"person_id\", \"item\", \"amount\", \"purchase_date\"])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"markdown","source":["#### Convert purchase_date to a date format using to_date function"],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql.functions import to_date\ntransDF = transDF.withColumn(\"purchase_date\", to_date(\"purchase_date\" , \"yyyy-mm-dd\"))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"markdown","source":["### Perform some DataFrames functions"],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql.functions import col\ntransDF.withColumn(\"id\", col(\"id\") * 2).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+---------+-----+------+-------------+\n id|person_id| item|amount|purchase_date|\n+---+---------+-----+------+-------------+\n  2|      123| Soap|   5.0|   2018-01-01|\n  4|      123|Fruit|  4.67|   2018-01-01|\n  6|      234| Soap|   5.0|   2018-01-01|\n  8|      234|Bread|  1.99|   2018-01-01|\n 10|      234| Milk|  4.55|   2018-01-01|\n 12|      345|Chips|  5.99|   2018-01-01|\n+---+---------+-----+------+-------------+\n\n</div>"]}}],"execution_count":9},{"cell_type":"code","source":["joinExpression = (  transDF[\"person_id\"] == personDF[\"id\"] )\njoinType = 'left_outer'\ndf = personDF.join(transDF,joinExpression,joinType)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":10},{"cell_type":"code","source":["display(df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>name</th><th>age</th><th>id</th><th>person_id</th><th>item</th><th>amount</th><th>purchase_date</th></tr></thead><tbody><tr><td>234</td><td>Doe</td><td>27</td><td>3</td><td>234</td><td>Soap</td><td>5.0</td><td>2018-01-01</td></tr><tr><td>234</td><td>Doe</td><td>27</td><td>4</td><td>234</td><td>Bread</td><td>1.99</td><td>2018-01-01</td></tr><tr><td>234</td><td>Doe</td><td>27</td><td>5</td><td>234</td><td>Milk</td><td>4.55</td><td>2018-01-01</td></tr><tr><td>123</td><td>John</td><td>25</td><td>1</td><td>123</td><td>Soap</td><td>5.0</td><td>2018-01-01</td></tr><tr><td>123</td><td>John</td><td>25</td><td>2</td><td>123</td><td>Fruit</td><td>4.67</td><td>2018-01-01</td></tr><tr><td>345</td><td>Jane</td><td>21</td><td>6</td><td>345</td><td>Chips</td><td>5.99</td><td>2018-01-01</td></tr><tr><td>456</td><td>Jimmy</td><td>45</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>"]}}],"execution_count":11},{"cell_type":"code","source":["from pyspark.sql.functions import sum, desc\ndf.groupBy(\"name\").agg(sum(\"amount\").alias(\"Total Spent\")).orderBy(desc(\"Total Spent\")).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+-----------+\n name|Total Spent|\n+-----+-----------+\n  Doe|      11.54|\n John|       9.67|\n Jane|       5.99|\nJimmy|       null|\n+-----+-----------+\n\n</div>"]}}],"execution_count":12},{"cell_type":"markdown","source":["### Let's make the following the SQL Way\n```\njoinExpression = (  transDF[\"person_id\"] == personDF[\"id\"] )\njoinType = 'left_outer'\ndf = personDF.join(transDF,joinExpression,joinType)\n\nfrom pyspark.sql.functions import sum, desc\ndf.groupBy(\"name\").agg(sum(\"amount\").alias(\"Total Spent\")).orderBy(desc(\"Total Spent\")).show()\n\n```"],"metadata":{}},{"cell_type":"code","source":["transDF.createOrReplaceTempView(\"transSQL\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":14},{"cell_type":"code","source":["personDF.createOrReplaceTempView(\"personSQL\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":15},{"cell_type":"code","source":["dfSQL = spark.sql(\"\"\"\nselect *\nfrom personSQL\nLeft join transSQL on (personSQL.id = transSQL.person_id)\n\"\"\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":16},{"cell_type":"code","source":["dfSQL.createOrReplaceTempView(\"dfSQL\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":17},{"cell_type":"code","source":["spark.sql(\"\"\"\nselect name, sum(amount) as `total amount` from dfSQL\ngroup by name\norder by `total amount` desc\n\"\"\").show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+------------+\n name|total amount|\n+-----+------------+\n  Doe|       11.54|\n John|        9.67|\n Jane|        5.99|\nJimmy|        null|\n+-----+------------+\n\n</div>"]}}],"execution_count":18},{"cell_type":"markdown","source":["#### In order to mount s3 to Databricks Execute the following:\n```\n#%fs mount s3a://Access key ID:Secret access key@bucketname /mnt/mys3\n```\n#### Make sure that you replace / with %2F in Access Key or Secret Key"],"metadata":{}},{"cell_type":"code","source":["%fs ls /mnt/"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">\tat com.databricks.backend.daemon.data.client.DbfsClient.send0(DbfsClient.scala:92)\n\tat com.databricks.backend.daemon.data.client.DbfsClient.sendIdempotent(DbfsClient.scala:54)\n\tat com.databricks.backend.daemon.data.client.DatabricksFileSystemV1.listStatus(DatabricksFileSystemV1.scala:180)\n\tat com.databricks.backend.daemon.data.client.DatabricksFileSystem.listStatus(DatabricksFileSystem.scala:143)\n\tat com.databricks.backend.daemon.dbutils.FSUtils$$anonfun$ls$1.apply(DBUtilsCore.scala:83)\n\tat com.databricks.backend.daemon.dbutils.FSUtils$$anonfun$ls$1.apply(DBUtilsCore.scala:82)\n\tat com.databricks.backend.daemon.dbutils.FSUtils$.com$databricks$backend$daemon$dbutils$FSUtils$$withFsSafetyCheck(DBUtilsCore.scala:78)\n\tat com.databricks.backend.daemon.dbutils.FSUtils$.ls(DBUtilsCore.scala:82)\n\tat com.databricks.dbutils_v1.impl.DbfsUtilsImpl.ls(DbfsUtilsImpl.scala:34)\n\tat linedd90cd7e18534b84a347c8b8befa258225.$read$$iw$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-346381476745883:1)\n\tat linedd90cd7e18534b84a347c8b8befa258225.$read$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-346381476745883:44)\n\tat linedd90cd7e18534b84a347c8b8befa258225.$read$$iw$$iw$$iw$$iw.&lt;init&gt;(command-346381476745883:46)\n\tat linedd90cd7e18534b84a347c8b8befa258225.$read$$iw$$iw$$iw.&lt;init&gt;(command-346381476745883:48)\n\tat linedd90cd7e18534b84a347c8b8befa258225.$read$$iw$$iw.&lt;init&gt;(command-346381476745883:50)\n\tat linedd90cd7e18534b84a347c8b8befa258225.$read$$iw.&lt;init&gt;(command-346381476745883:52)\n\tat linedd90cd7e18534b84a347c8b8befa258225.$read.&lt;init&gt;(command-346381476745883:54)\n\tat linedd90cd7e18534b84a347c8b8befa258225.$read$.&lt;init&gt;(command-346381476745883:58)\n\tat linedd90cd7e18534b84a347c8b8befa258225.$read$.&lt;clinit&gt;(command-346381476745883)\n\tat linedd90cd7e18534b84a347c8b8befa258225.$eval$.$print$lzycompute(&lt;notebook&gt;:7)\n\tat linedd90cd7e18534b84a347c8b8befa258225.$eval$.$print(&lt;notebook&gt;:6)\n\tat linedd90cd7e18534b84a347c8b8befa258225.$eval.$print(&lt;notebook&gt;)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat scala.tools.nsc.interpreter.IMain$ReadEvalPrint.call(IMain.scala:793)\n\tat scala.tools.nsc.interpreter.IMain$Request.loadAndRun(IMain.scala:1054)\n\tat scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:645)\n\tat scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:644)\n\tat scala.reflect.internal.util.ScalaClassLoader$class.asContext(ScalaClassLoader.scala:31)\n\tat scala.reflect.internal.util.AbstractFileClassLoader.asContext(AbstractFileClassLoader.scala:19)\n\tat scala.tools.nsc.interpreter.IMain$WrappedRequest.loadAndRunReq(IMain.scala:644)\n\tat scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:576)\n\tat scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:572)\n\tat com.databricks.backend.daemon.driver.DriverILoop.execute(DriverILoop.scala:199)\n\tat com.databricks.backend.daemon.driver.ScalaDriverLocal$$anonfun$repl$1.apply$mcV$sp(ScalaDriverLocal.scala:190)\n\tat com.databricks.backend.daemon.driver.ScalaDriverLocal$$anonfun$repl$1.apply(ScalaDriverLocal.scala:190)\n\tat com.databricks.backend.daemon.driver.ScalaDriverLocal$$anonfun$repl$1.apply(ScalaDriverLocal.scala:190)\n\tat com.databricks.backend.daemon.driver.DriverLocal$TrapExitInternal$.trapExit(DriverLocal.scala:590)\n\tat com.databricks.backend.daemon.driver.DriverLocal$TrapExit$.apply(DriverLocal.scala:545)\n\tat com.databricks.backend.daemon.driver.ScalaDriverLocal.repl(ScalaDriverLocal.scala:190)\n\tat com.databricks.backend.daemon.driver.DriverLocal$$anonfun$execute$8.apply(DriverLocal.scala:323)\n\tat com.databricks.backend.daemon.driver.DriverLocal$$anonfun$execute$8.apply(DriverLocal.scala:303)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:235)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:230)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:47)\n\tat com.databricks.logging.UsageLogging$class.withAttributionTags(UsageLogging.scala:268)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:47)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:303)\n\tat com.databricks.backend.daemon.driver.DriverWrapper$$anonfun$tryExecutingCommand$2.apply(DriverWrapper.scala:591)\n\tat com.databricks.backend.daemon.driver.DriverWrapper$$anonfun$tryExecutingCommand$2.apply(DriverWrapper.scala:591)\n\tat scala.util.Try$.apply(Try.scala:192)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:586)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.getCommandOutputAndError(DriverWrapper.scala:477)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:544)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:383)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:330)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:216)\n\tat java.lang.Thread.run(Thread.java:748)</div>"]}}],"execution_count":20},{"cell_type":"code","source":["dfSQL.toPandas()"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["dfSQL.drop(\"id\").write.format(\"json\").option(\"path\", \"/mnt/mys3/demo\").save()"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["df_train = spark.read.format(\"csv\").option(\"inferSchema\", \"True\").option(\"header\", \"True\")\\\n.option(\"path\", \"/mnt/mys3/test/train.csv\").load()"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["df_train.show(5)"],"metadata":{},"outputs":[],"execution_count":24}],"metadata":{"name":"Meetup","notebookId":346381476745863},"nbformat":4,"nbformat_minor":0}
