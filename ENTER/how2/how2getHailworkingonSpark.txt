





-------------------------------------------------------------------------------------------------------------------------------
advice
		
	go to discuss.hail.is and search on 'your item'
-------------------------------------------------------------------------------------------------------------------------------














-------------------------------------------------------------------------------------------------------------------------------
These are Spark config options that Hail requires – they’re not really documented, which is a problem. When Hail creates a SparkContext, it configures it properly, but when one is passed in (hc = HailContext(sc)) we have to check.

How is your spark context created? Is it created from a pyspark submit command? 
You can configure most Spark startup actions with a --conf option, e.g. --conf spark.sql.files.maxPartitionBytes=1000000000



conf = SparkConf()
conf.set('spark.sql.files.maxPartitionBytes
','60000000000')
conf.set('spark.sql.files.openCostInBytes','60000000000')
conf.set('master','local[*]')
conf.set('spark.submit.deployMode', u'client')
conf.set('spark.app.name', u'PyTest')
sc = SparkContext(conf=conf)



or



In [1]: from pyspark import *

In [2]: from hail import *

In [3]: conf = SparkConf()
   ...: conf.set('spark.sql.files.maxPartitionBytes','60000000000')
   ...: conf.set('spark.sql.files.openCostInBytes','60000000000')
   ...: conf.set('master','local[*]')
   ...: conf.set('spark.submit.deployMode', u'client')
   ...: conf.set('spark.app.name', u'PyTest')
   ...: sc = SparkContext(conf=conf)

In [4]: hc = HailContext(sc)
hail: info: SparkUI: http://192.168.1.2:4040
-------------------------------------------------------------------------------------------------------------------------------













-------------------------------------------------------------------------------------------------------------------------------
from hail import *
hc = HailContext()
-------------------------------------------------------------------------------------------------------------------------------

















-------------------------------------------------------------------------------------------------------------------------------
from pyspark import *
from hail import *
conf = SparkConf()
conf.set('spark.sql.files.maxPartitionBytes','60000000000') 
conf.set('spark.sql.files.openCostInBytes','60000000000') 
conf.set('spark.driver.cores','1') #test with 1 core
sc = SparkContext(conf=conf)
hc = HailContext(sc)
-------------------------------------------------------------------------------------------------------------------------------








-------------------------------------------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------------------------------------------





-------------------------------------------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------------------------------------------





-------------------------------------------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------------------------------------------





-------------------------------------------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------------------------------------------





-------------------------------------------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------------------------------------------





-------------------------------------------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------------------------------------------





-------------------------------------------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------------------------------------------




